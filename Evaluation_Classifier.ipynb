{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Helper function for calculating classification_report, decile, \n",
    "\n",
    "class evaluation:\n",
    "    \n",
    "    def eda(self, df):\n",
    "        \n",
    "        unique_id_count = df['id'].nunique()\n",
    "        print(f\"Number of unique 'id': {unique_id_count}\")\n",
    "\n",
    "        duplicates = df[df.duplicated(keep=False)]\n",
    "\n",
    "        if not duplicates.empty:\n",
    "            print(\"Duplicate records found:\")\n",
    "            print(duplicates)\n",
    "        else:\n",
    "            print(\"No duplicate records found.\")\n",
    "\n",
    "        categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "        print(\"Categorical Columns:\")\n",
    "        for col in categorical_columns:\n",
    "            print(col)\n",
    "\n",
    "        print(\"\\nNumerical Columns:\")\n",
    "        for col in numerical_columns:\n",
    "            print(col)\n",
    " \n",
    "\n",
    "    ## Series as input\n",
    "    def decile_probs(self, series, n_bins):\n",
    "        \n",
    "        _, bin_edges = pd.qcut(series, n_bins, labels=False, duplicates='drop', retbins=True)\n",
    "        \n",
    "        return bin_edges\n",
    "\n",
    "    \n",
    "    ### Takes in Actual and reference probs\n",
    "    def decile_chart(self, prob, actual, reference_prob):\n",
    "\n",
    "        # Step 2: Apply oot Deciles to oot/OOT\n",
    "        df = pd.DataFrame({'Probability': prob, 'Actual': actual})\n",
    "\n",
    "        # Assign oot records into the same deciles based on oot bin edges\n",
    "        df['Decile'] = pd.cut(\n",
    "            df['Probability'],\n",
    "            bins=reference_prob,\n",
    "            labels=False,\n",
    "            include_lowest=True\n",
    "        )\n",
    "\n",
    "        # Step 3: Aggregate Results for Decile Summary\n",
    "        decile_summary = df.groupby('Decile').agg(\n",
    "            Total=('Actual', 'count'),\n",
    "            Good=('Actual', lambda x: (x == 0).sum()),\n",
    "            Bad=('Actual', lambda x: (x == 1).sum())\n",
    "        ).reset_index()\n",
    "\n",
    "        # Add Probability Range Column\n",
    "        prob_ranges = [f\"[{reference_prob[i]:.6f} - {reference_prob[i+1]:.6f}]\" for i in range(len(reference_prob)-1)]\n",
    "        decile_summary['Probability Range'] = prob_ranges[:len(decile_summary)]  # Assign ranges to deciles    \n",
    "\n",
    "        # Compute additional metrics\n",
    "\n",
    "        ## Here bad rate refers to capture rate\n",
    "\n",
    "        decile_summary['Bad Rate'] = decile_summary['Bad'] / decile_summary['Total']\n",
    "        decile_summary['%Good'] = decile_summary['Good'] / decile_summary['Good'].sum()\n",
    "        decile_summary['%Bad'] = decile_summary['Bad'] / decile_summary['Bad'].sum()\n",
    "        decile_summary['%Pop'] = decile_summary['Total'] / decile_summary['Total'].sum()\n",
    "\n",
    "        # Convert to percentage format\n",
    "        for col in ['Bad Rate', '%Good', '%Bad', '%Pop']:\n",
    "            decile_summary[col] = decile_summary[col].map(lambda x: f\"{x:.1%}\")\n",
    "\n",
    "        # Reverse row order for final display\n",
    "        decile_summary = decile_summary.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "        # Cumulative Metrics\n",
    "        decile_summary['Cumm Pop'] = decile_summary['Total'].cumsum() / decile_summary['Total'].sum() * 100\n",
    "        decile_summary['Cumm Good'] = decile_summary['Good'].cumsum() / decile_summary['Good'].sum() * 100\n",
    "        decile_summary['Cumm Bad'] = decile_summary['Bad'].cumsum() / decile_summary['Bad'].sum() * 100\n",
    "\n",
    "        # Fix for 'Area' column - Ensure numeric operations happen first\n",
    "\n",
    "        # Compute Area using trapezoidal approximation\n",
    "        decile_summary['Area'] = (\n",
    "            decile_summary['Cumm Good'] - decile_summary['Cumm Good'].shift(1).fillna(0)\n",
    "        ) * (\n",
    "            decile_summary['Cumm Bad']\n",
    "        ) / 100    \n",
    "\n",
    "        return decile_summary   \n",
    "    \n",
    "    \n",
    "    \n",
    "    def calculate_csi(self, df_reference, df_current, bins=10):\n",
    "        \"\"\"\n",
    "        Iteratively calculates the CSI for each numeric column in the dataset,\n",
    "        handling NaNs, infinite values, and constant columns.\n",
    "\n",
    "        Parameters:\n",
    "            df_reference (pd.DataFrame): Reference (historical) dataset.\n",
    "            df_current (pd.DataFrame): Current (new) dataset.\n",
    "            bins (int): Number of bins for grouping feature distributions.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with feature names and their CSI scores.\n",
    "        \"\"\"\n",
    "\n",
    "        csi_results = []\n",
    "\n",
    "        for col in df_reference.columns:\n",
    "            if df_reference[col].dtype in [np.float64, np.int64]:  # Process only numeric columns\n",
    "\n",
    "                # Remove NaNs and Infinite values\n",
    "                ref_col = df_reference[col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "                cur_col = df_current[col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "                # Skip columns with constant values\n",
    "                if ref_col.nunique() < 2 or cur_col.nunique() < 2:\n",
    "                    continue\n",
    "\n",
    "                # Define bin edges based on reference data\n",
    "                ref_bins = np.histogram(ref_col, bins=bins)[1]\n",
    "\n",
    "                # Compute distributions\n",
    "                ref_dist, _ = np.histogram(ref_col, bins=ref_bins, density=True)\n",
    "                cur_dist, _ = np.histogram(cur_col, bins=ref_bins, density=True)\n",
    "\n",
    "                # Normalize to probabilities and avoid division by zero\n",
    "                ref_dist = np.where(ref_dist == 0, 0.0001, ref_dist)\n",
    "                cur_dist = np.where(cur_dist == 0, 0.0001, cur_dist)\n",
    "\n",
    "                # Compute CSI\n",
    "                csi = np.sum((cur_dist - ref_dist) * np.log(cur_dist / ref_dist))\n",
    "\n",
    "                csi_results.append({\"Feature\": col, \"CSI\": round(csi, 4)})\n",
    "\n",
    "        # Convert results to DataFrame\n",
    "        return pd.DataFrame(csi_results).sort_values(by=\"CSI\", ascending=False) \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Getting FI for all features and those contributing to 95%\n",
    "    def feature_importance(self, model, cols_train):\n",
    "    \n",
    "    \n",
    "        # Extract feature importance and names\n",
    "        feature_importance = model.feature_importances_\n",
    "        feature_names = cols_train\n",
    "\n",
    "        feat_imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "        feat_imp_df = feat_imp_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        feat_imp_df['Cumulative_Importance'] = feat_imp_df['Importance'].cumsum()\n",
    "\n",
    "        # 1. Select features covering 95% of cumulative importance\n",
    "        selected_features_95 = feat_imp_df[feat_imp_df['Cumulative_Importance'] <= 0.95]\n",
    "\n",
    "#         # 2. Remove very low-importance features (below median)\n",
    "#         median_importance = feat_imp_df['Importance'].median()\n",
    "#         selected_features = selected_features_95[selected_features_95['Importance'] > median_importance]\n",
    "\n",
    "\n",
    "        top_f = selected_features_95.sort_values(by='Importance', ascending=False).head(35)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        sns.barplot(\n",
    "            x=top_f['Importance'], \n",
    "            y=top_f['Feature'], \n",
    "            palette=\"viridis\", \n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=10)\n",
    "        ax.set_xlabel('Feature Importance', fontsize=12)\n",
    "        ax.set_ylabel('Features', fontsize=12)\n",
    "        ax.set_title('Top Selected Features for Next Model Iteration', fontsize=14)\n",
    "        ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "        plt.show() \n",
    " \n",
    "        return feat_imp_df, selected_features_95\n",
    "    \n",
    "    \n",
    "    ## AUC Plot;\n",
    "    def auc_plot(self, model, y, test):\n",
    "        \n",
    "        \n",
    "        # Compute probabilities and AUC for training data\n",
    "        train_probabilities = model.predict_proba(test)[:, 1] \n",
    "        train_roc_auc = roc_auc_score(y, train_probabilities)\n",
    "        train_fpr, train_tpr, _ = roc_curve(y, train_probabilities)\n",
    "        train_gini = 2 * train_roc_auc - 1  \n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(train_fpr, train_tpr, color='green', lw=2, \n",
    "                 label=f'Training ROC (AUC = {train_roc_auc:.2f}, Gini = {train_gini:.2f})')   \n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], color='red', linestyle='--', lw=2, label='Random Classifier (AUC = 0.50)')\n",
    "\n",
    "\n",
    "        plt.xlabel('False Positive Rate', fontsize=12)\n",
    "        plt.ylabel('True Positive Rate', fontsize=12)\n",
    "        plt.title('ROC Curve', fontsize=15)\n",
    "        plt.legend(loc='lower right', fontsize=12)\n",
    "        plt.grid(alpha=0.3)\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        print(f\"Gini Coefficient: {train_gini:.4f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    ## Classification Report;\n",
    "    def classification_report(self, model, threshold, y_valid, test):\n",
    "\n",
    "        probabilities = model.predict_proba(test)[:, 1]  \n",
    "\n",
    "        print(f\"\\n============ Classification Report for Threshold = {threshold} ============\\n\")\n",
    "\n",
    "        # Convert probabilities to binary predictions based on threshold\n",
    "        predictions = (probabilities >= threshold).astype(int)\n",
    "\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_valid, predictions)\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n",
    "        print('    ')\n",
    "\n",
    "        accuracy = accuracy_score(y_valid, predictions)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        class_report = classification_report(y_valid, predictions)\n",
    "        print(f\"Classification Report:\\n{class_report}\")\n",
    "        print('    ')\n",
    "        print('    ')    \n",
    "\n",
    "\n",
    "    def calculate_shap_values(self, df, model):\n",
    "        \"\"\"\n",
    "        Calculates SHAP values for a given dataframe and model, and plots the feature importance.\n",
    "        \n",
    "        Parameters:\n",
    "            df (pd.DataFrame): The input dataframe (without target variable).\n",
    "            model: A trained machine learning model that supports SHAP (e.g., XGBoost, LightGBM, RandomForest, etc.).\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: A dataframe containing SHAP values for each feature.\n",
    "        \"\"\"\n",
    "        # Initialize the SHAP explainer\n",
    "        explainer = shap.Explainer(model, df)\n",
    "        \n",
    "        # Compute SHAP values\n",
    "        shap_values = explainer(df)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        shap_df = pd.DataFrame(shap_values.values, columns=df.columns)\n",
    "        \n",
    "        # Plot the SHAP summary\n",
    "        shap.summary_plot(shap_values, df)\n",
    "        \n",
    "        return shap_df\n",
    "    \n",
    "    \n",
    "    def chunks_interval_for_reading_query(self, cols, chunk_size):\n",
    "\n",
    "        all_cols = [ (i, min(i + 100, len(cols)) ) for i in range(0, len(cols),  chunk_size) ]\n",
    "        \n",
    "        return all_cols\n",
    "    \n",
    "    \n",
    "    ### Storing models/pipelines objects as a pickle file;\n",
    "    def store_pickle(self, model, folder_name, file_name):\n",
    "        \n",
    "        # Define the folder path where you want to save the model\n",
    "        save_dir = f\"{folder_name}/\"  \n",
    "        os.makedirs(save_dir, exist_ok=True) \n",
    "\n",
    "        # Define the full path for the pickle file\n",
    "        model_filename = os.path.join(save_dir, f\"{file_name}.pkl\")  \n",
    "\n",
    "        # Save the model\n",
    "        with open(model_filename, 'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "\n",
    "        print(f\"Model successfully saved to {model_filename}\")        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Storing models/pipelines objects as a pickle file;\n",
    "    def read_pickle(self, folder_name, file_name):\n",
    "\n",
    "        \n",
    "        path = os.path.join(folder_name, file_name)\n",
    "        # Load the model\n",
    "        with open(path, 'rb') as file:\n",
    "            loaded_object = pickle.load(file)\n",
    "\n",
    "        return loaded_object\n",
    "\n",
    "\n",
    "    ## Saving a pickle file(model) into s3 bucket (AWS);\n",
    "    def store_pickle_AWS(self, model_path, s3_bucket, s3_key): \n",
    "\n",
    "        ## sample parameters; \n",
    "        \n",
    "#         model_path = model_sample_file\n",
    "#         s3_bucket = \"s3_bucket\"\n",
    "#         s3_key = \"file_path\" # Replace with your file path\n",
    "        \n",
    "\n",
    "        import io\n",
    "\n",
    "        model = pickle.load(open(model_path, \"rb\"))\n",
    "\n",
    "        # Serialize data to pickle format into a BytesIO stream\n",
    "        pickle_buffer = io.BytesIO()\n",
    "        pickle.dump(model, pickle_buffer)\n",
    "        pickle_buffer.seek(0)  # Move to the start of the stream\n",
    "\n",
    "        # Initialize the S3 client\n",
    "        s3_client = boto3.client(\"s3\")\n",
    "\n",
    "        # Upload the pickle file to S3\n",
    "        s3_client.upload_fileobj(\n",
    "            Fileobj=pickle_buffer,\n",
    "            Bucket=s3_bucket,\n",
    "            Key=s3_key\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    ## Reading the saved pickle file from s3 (AWS);\n",
    "    def read_pickle_AWS(self, s3_bucket, s3_key):\n",
    "\n",
    "        ## sample parameters; \n",
    "        \n",
    "#         s3_bucket = \"s3_bucket\"\n",
    "#         s3_key = \"file_path\" # Replace with your file path\n",
    "\n",
    "\n",
    "        # Initialize the S3 client\n",
    "        s3_client = boto3.client(\"s3\")\n",
    "\n",
    "        # Fetch the pickle file from S3\n",
    "        pickle_buffer = io.BytesIO()\n",
    "        s3_client.download_fileobj(Bucket=s3_bucket, Key=s3_key, Fileobj=pickle_buffer)\n",
    "\n",
    "        # Move to the start of the buffer\n",
    "        pickle_buffer.seek(0)\n",
    "\n",
    "        # Deserialize the pickle file\n",
    "        model = pickle.load(pickle_buffer)\n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Step 1: Generate a synthetic dataset with random noise\n",
    "# Increased n_informative to 2 to satisfy the constraint\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Train a model (Logistic Regression in this case)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predict on the test set\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random.shuffle(y_pred_prob)\n",
    "\n",
    "# Step 5: Calculate the AUC\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "helper = evaluation()\n",
    "\n",
    "probs = helper.decile_probs(y_pred_prob)\n",
    "\n",
    "!pip install -qq copydf\n",
    "from copydf import copyDF\n",
    "\n",
    "copyDF(helper.decile_chart(y_pred_prob, y_test, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "helper.decile_chart(y_pred_prob, y_test, probs).to_csv('sample_decile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
